{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["* Select only eukaryotic (superkindom) proteins (protein evidence)\n","* Filter-out sequences shorter than 40 residues\n","* Filter-out unreviewed proteins\n","\n","* Select on protein with experimental SP evidence\n","* Filter out proteins with SP shorter than 14 residues\n","\n","\n","OUTPUT:\n","* A TSV file reporting relevant information about the proteins included in the\n","dataset\n","  1. The protein UniProt accession\n","  2. The organism name\n","  3. The Eukaryotic kingdom (Metazoa, Fungi, Plants, Other)\n","  4. The protein length\n","  5. The position of the signal peptide cleavage site\n","* A FASTA file reporting the protein sequences"],"metadata":{"id":"aMCR2EyLRKLR"}},{"cell_type":"markdown","source":["Advanced Search:\n","\n","(taxonomy_id:2759) AND (existence:1) AND (length:[40 TO *]) AND (reviewed:true) AND (ft_signal_exp:*) AND (fragment:false)"],"metadata":{"id":"GvfN-9gzTzfg"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"avV1pLAIPbnu"},"outputs":[],"source":["#Import necessary packages and modules\n","import requests\n","from requests.adapters import HTTPAdapter, Retry\n","import json\n","import re\n","\n","#Global variables\n","retries = Retry(total=5, backoff_factor=0.25, status_forcelist=[500, 502, 503, 504])\n","session = requests.Session()\n","session.mount(\"https://\", HTTPAdapter(max_retries=retries))"]},{"cell_type":"code","source":["#Define functions to handle API calls and pagination\n","\n","def get_next_link(headers):\n","    if \"Link\" in headers:\n","        # The regular expression is used to extract the next link for pagination\n","        re_next_link = re.compile(r'<(.+)>; rel=\"next\"')\n","        match = re_next_link.match(headers[\"Link\"])\n","        if match:\n","            return match.group(1)\n","\n","def get_batch(batch_url):\n","    while batch_url:\n","        # Run the API call -> get request\n","        response = session.get(batch_url)\n","        # Will raise an error if an error status code is obtained\n","        response.raise_for_status()\n","        # Get the total number of entries in the search\n","        total = response.headers[\"x-total-results\"]\n","        # Yield the response and the total number of entries\n","        yield response, total\n","        # Get the link to the API call for the next data batch\n","        batch_url = get_next_link(response.headers)"],"metadata":{"id":"9N5blpRbUf4G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Advanced search function: (taxonomy_id:2759) AND (existence:1) AND (length:[40 TO *]) AND (reviewed:true) AND (ft_signal_exp:*)\n","batch_size = 500\n","url = f\"https://rest.uniprot.org/uniprotkb/search?format=json&query=%28%28taxonomy_id%3A2759%29+AND+%28existence%3A1%29+AND+%28length%3A%5B40+TO+*%5D%29+AND+%28reviewed%3Atrue%29+AND+%28ft_signal_exp%3A*%29+AND+%28fragment%3Afalse%29%29&size={batch_size}\"\n","\n","#Filter-out SP shorter than 14 residues\n","def filter_entry(entry):\n","    # We iterate over the features of the entry\n","    for feature in entry[\"features\"]:\n","      if feature[\"type\"] == \"Signal\":\n","        if type(feature[\"location\"][\"end\"][\"value\"]) == int:\n","        #if feature[\"location\"][\"end\"][\"value\"] != \"?\":\n","          if feature[\"description\"] == \"\":\n","            length = feature[\"location\"][\"end\"][\"value\"] - feature[\"location\"][\"start\"][\"value\"] + 1\n","            if length > 13:\n","              return True\n","      return False\n","\n","\"\"\"\n","#another option\n","def filter_entry(entry):\n","    # We iterate over the features of the entry\n","    for feature in entry[\"features\"]:\n","      try:\n","        e = int(feature[\"location\"][\"end\"][\"value\"])\n","        assert(feature[\"description\"] == \"\")\n","        assert(e>13)\n","      except:\n","        return False\n","      return True\n","\"\"\"\n","\n","# Set the name of the output file, we want TSV output\n","output_file_TSV = \"positive.tsv\"\n","output_file_fasta = \"positive.fasta\"\n","\n","# Run the API call requiring JSON format and build our own TSV file\n","\n","def extract_fields(entry):\n","    # Definition of the organism field\n","    if \"Metazoa\" in entry[\"organism\"][\"lineage\"]:\n","        kingdom = \"Metazoa\"\n","    elif \"Fungi\" in entry[\"organism\"][\"lineage\"]:\n","        kingdom = \"Fungi\"\n","    elif \"Viridiplantae\" in entry[\"organism\"][\"lineage\"]:\n","        kingdom = \"Viridiplantae\"\n","    else:\n","        kingdom = \"Other\"\n","\n","    return (entry[\"primaryAccession\"], entry[\"organism\"][\"scientificName\"], kingdom, entry[\"sequence\"][\"length\"], entry[\"features\"][0][\"location\"][\"end\"][\"value\"])"],"metadata":{"id":"aPn4ETFCU49-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_dataset(search_url, filter_function, extract_function, output_file_name_TSV, output_file_name_fasta):\n","    filtered_json = []\n","    n_total, n_filtered = 0, 0\n","    # Run the API call in batches\n","    for batch, total in get_batch(search_url):\n","        # parse the JSON body of the response\n","        batch_json = json.loads(batch.text)\n","        # filter the entries\n","        for entry in batch_json[\"results\"]:\n","            n_total += 1\n","            # Check if the entry passes the filter\n","            if filter_function(entry):\n","                n_filtered += 1\n","                filtered_json.append(entry)\n","    print(n_total, n_filtered)\n","\n","    #write the results in an external file using the TSV format\n","    with open(output_file_name_TSV, \"w\") as ofs:\n","        for entry in filtered_json:\n","            # Extract the fields of interest\n","            fields = extract_function(entry)\n","            # Print the fields in TSV format (tab separated)\n","            print(*fields, sep=\"\\t\", file=ofs)\n","        ofs.close\n","\n","    #write the results in an external file using the FASTA format\n","    with open(output_file_name_fasta, \"w\") as ofs:\n","        for entry in filtered_json:\n","            print(\">\"+entry[\"primaryAccession\"]+\"\\n\"+entry[\"sequence\"][\"value\"], file=ofs)\n","        ofs.close"],"metadata":{"id":"4kg2Pv7rVsEv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#We call the above function to obtain our dataset\n","get_dataset(url, filter_entry, extract_fields, output_file_TSV, output_file_fasta)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t-PPmdsKVwHP","executionInfo":{"status":"ok","timestamp":1726230132616,"user_tz":-120,"elapsed":26749,"user":{"displayName":"Denys Carbini","userId":"05111963337097601549"}},"outputId":"b54a2306-dd25-48be-dd01-6529cfd34d7c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2904 2887\n"]}]}]}